{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import HeteroData, InMemoryDataset, download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gowalla(InMemoryDataset):\n",
    "    url = 'https://snap.stanford.edu/data/loc-gowalla_totalCheckins.txt.gz'\n",
    "  \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform, pre_transform,\n",
    "                         force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0], data_cls=HeteroData)\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return ['loc-gowalla_totalCheckins.txt', 'filtered_total.txt', 'user_id_map.txt', 'item_id_map.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "    \n",
    "    @property\n",
    "    def ziped_file_name(self) -> str:\n",
    "        return 'loc-gowalla_totalCheckins.txt.gz'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        import gzip\n",
    "\n",
    "        if not osp.isfile(osp.join(self.root, 'data/Gowalla/loc-gowalla_totalCheckins.txt.gz')):\n",
    "            download_url(f'{self.url}', self.root)\n",
    "        if not osp.isfile(osp.join(self.root,'data/Gowalla/raw/loc-gowalla_totalCheckins.txt')): \n",
    "            os.system(f'gzip -d {osp.join(self.root,\"/data/Gowalla/loc-gowalla_totalCheckins.txt.gz\")}')\n",
    "            os.system(f'mv {osp.join(self.root,\"/data/Gowalla/loc-gowalla_totalCheckins.txt\")} {osp.join(self.root,\"/data/Gowalla/loc-gowalla_totalCheckins.txt.gz\")}')\n",
    "    \n",
    "    def filter(self, df, threshold):\n",
    "            df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[0]),sep = '\\t', names = ['user', 'date', 'long', 'lat', 'item'])\n",
    "            filtered_df = self.filtering(df, threshold)\n",
    "            processed_df, user_id, item_id  = self.refactoring_from_0(filtered_df)\n",
    "            processed_df.to_csv(osp.join(self.raw_dir, self.raw_file_names[1]),sep=\" \", index=False, header=None)\n",
    "            user_id.to_csv(osp.join(self.raw_dir, self.raw_file_names[2]),sep=\" \", index=False, header=None)\n",
    "            item_id.to_csv(osp.join(self.raw_dir, self.raw_file_names[3]),sep=\" \", index=False, header=None)\n",
    "\n",
    "    def refactoring_from_0(self, df):\n",
    "        out_df = pd.DataFrame() \n",
    "        \n",
    "        original_uid = np.sort(df['user'].unique())\n",
    "        original_iid = np.sort(df['item'].unique())\n",
    "\n",
    "        u_range = range(len(original_uid))\n",
    "        i_range = range(len(original_iid))\n",
    "\n",
    "        uid_mapping = { o_id: n_id for o_id, n_id in zip(original_uid, u_range)} # 원래 유저 아이디 (중간중간 비어있음) : 순서대로 유저 아이디\n",
    "        iid_mapping = { o_id: n_id for o_id, n_id in zip(original_iid,i_range)} # 원래 아이템 아이디 : 순서대로 아이템 아이디\n",
    "\n",
    "        uid_map = pd.DataFrame({'o_id' : list(uid_mapping.keys()), 'n_id' : list(uid_mapping.values())})\n",
    "\n",
    "        iid_map = pd.DataFrame({'o_id' : list(iid_mapping.keys()),'n_id':list(iid_mapping.values())})\n",
    "\n",
    "\n",
    "        out_df['user'] = df['user'].map(uid_mapping)\n",
    "        out_df['item'] = df['item'].map(iid_mapping)\n",
    "        out_df['time'] = df['time']\n",
    "        return out_df, uid_map, iid_map\n",
    "\n",
    "    def filtering(self, df, threshold) :\n",
    "        fdf = df\n",
    "        while fdf.user.value_counts().min() < threshold or fdf.item.value_counts().min() < threshold:\n",
    "            df_item = fdf.groupby('item').count()\n",
    "            df_item = df_item[df_item.user < threshold]\n",
    "            li = df_item.index.to_list()\n",
    "            fdf = fdf.drop(fdf.loc[fdf.item.isin(li)].index)\n",
    "            # print_info(fdf)\n",
    "            df_usr = fdf.groupby('user').count()\n",
    "            df_usr = df_usr[df_usr.item < threshold]\n",
    "            li = df_usr.index.to_list()\n",
    "            fdf = fdf.drop(fdf.loc[fdf.user.isin(li)].index)\n",
    "            # print_info(fdf)\n",
    "            # print(f\"Total Edges : {len(fdf)}\\nTotal User : {len(fdf['user'].unique())}\\nTotal item : {len(fdf['item'].unique())} \\\n",
    "            #             \\nMin Interaction Per user : {fdf.user.value_counts().min()} \\\n",
    "            #             \\nMax Interaction Per user : {fdf.user.value_counts().max()} \\\n",
    "            #             \\nAvg Interaction Per user : {fdf.user.value_counts().mean()}\\\n",
    "            #             \\nMin Interaction Per item : {fdf.item.value_counts().min()} \\\n",
    "            #             \\nMax Interaction Per item : {fdf.item.value_counts().max()} \\\n",
    "            #             \\nAvg Interaction Per item : {fdf.item.value_counts().mean()}\")\n",
    "        \n",
    "        fdf = fdf.reset_index().drop(columns = ['index'])\n",
    "        return fdf\n",
    "\n",
    "    def process(self) -> None:\n",
    "        data = HeteroData()\n",
    "\n",
    "        # Process number of nodes for each node type:\n",
    "        node_types = ['user', 'item']\n",
    "\n",
    "        \n",
    "        if osp.isfile({osp.join(self.root,f\"/data/Gowalla/raw/{self.raw_file_name[1]}\")}) \\\n",
    "            and osp.isfile({osp.join(self.root,f\"/data/Gowalla/raw/{self.raw_file_name[2]}\")}) \\\n",
    "                and osp.isfile({osp.join(self.root,f\"/data/Gowalla/raw/{self.raw_file_name[3]}\")}):\n",
    "            df = read_csv(osp.join(self.raw_dir, self.raw_file_names[0]), names = ['user', 'item', 'time'])\n",
    "        else:\n",
    "            df = read_csv(osp.join(self.raw_dir, self.raw_file_names[0]), names = ['user', 'item', 'time'])\n",
    "            filter(df, threshold)\n",
    "            df = read_csv(osp.join(self.raw_dir, self.raw_file_names[1]), names = ['user', 'item', 'time'])\n",
    "    \n",
    "        for node_type in node_types :\n",
    "            data[node_type].num_nodes = len(df[node_type].unique())\n",
    "\n",
    "        # Process edge information for training and testing:\n",
    "        attr_names = ['edge_index', 'edge_label_index']\n",
    "\n",
    "        for path, attr_name in zip(self.raw_paths[2:], attr_names):\n",
    "            rows, cols = [], []\n",
    "            with open(path) as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                indices = line.strip().split(' ')\n",
    "                for dst in indices[1:]:\n",
    "                    rows.append(int(indices[0]))\n",
    "                    cols.append(int(dst))\n",
    "            index = torch.tensor([rows, cols])\n",
    "\n",
    "            data['user', 'rates', 'book'][attr_name] = index\n",
    "            if attr_name == 'edge_index':\n",
    "                data['book', 'rated_by', 'user'][attr_name] = index.flip([0])\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        self.save([data], self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Gowalla' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGowalla\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGowalla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 13\u001b[0m, in \u001b[0;36mGowalla.__init__\u001b[0;34m(self, root, transform, pre_transform, force_reload, filter)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      7\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mfilter\u001b[39m : \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m], data_cls\u001b[38;5;241m=\u001b[39mHeteroData)\n",
      "File \u001b[0;32m/mnt/extra/home/jiwon/pygbased/.conda/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:81\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     force_reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data: Optional[BaseData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/extra/home/jiwon/pygbased/.conda/lib/python3.9/site-packages/torch_geometric/data/dataset.py:112\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_reload \u001b[38;5;241m=\u001b[39m force_reload\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_download:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process()\n",
      "File \u001b[0;32m/mnt/extra/home/jiwon/pygbased/.conda/lib/python3.9/site-packages/torch_geometric/data/dataset.py:229\u001b[0m, in \u001b[0;36mDataset._download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    228\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 37\u001b[0m, in \u001b[0;36mGowalla.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip -d ./data/Gowalla/loc-gowalla_totalCheckins.txt.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m     os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmv ./data/Gowalla/loc-gowalla_totalCheckins.txt ./data/Gowalla/raw/loc-gowalla_totalCheckins.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m:\n\u001b[1;32m     38\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_file_names[\u001b[38;5;241m0\u001b[39m]),sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     39\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiltering(df)\n",
      "File \u001b[0;32m/mnt/extra/home/jiwon/pygbased/.conda/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:318\u001b[0m, in \u001b[0;36mInMemoryDataset.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    315\u001b[0m         data_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()]\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(data_list)[key]\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Gowalla' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "path = osp.join('./', 'data', 'Gowalla')\n",
    "dataset = Gowalla(path, filter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=107092 },\n",
       "  item={ num_nodes=1280969 }\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1621245/795434842.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ss =torch.load('/home/jiwon/Jiwon_Rsch/mount/pygbased/data/Gowalla/processed/data.pt')\n"
     ]
    }
   ],
   "source": [
    "ss = torch.load('/home/jiwon/Jiwon_Rsch/mount/pygbased/data/Gowalla/processed/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_global_store': {},\n",
       "  'user': {'num_nodes': 107092},\n",
       "  'item': {'num_nodes': 1280969}},\n",
       " None,\n",
       " torch_geometric.data.hetero_data.HeteroData)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=107092 },\n",
       "  item={ num_nodes=1280969 }\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
