{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import HeteroData, InMemoryDataset, download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Gowalla(InMemoryDataset):\n",
    "    url = 'https://snap.stanford.edu/data/loc-gowalla_totalCheckins.txt.gz'\n",
    "  \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "        core: int = None,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform, pre_transform,\n",
    "                         force_reload=force_reload)\n",
    "        self.core = core\n",
    "        self.load(self.processed_paths[0], data_cls=HeteroData)\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return ['loc-gowalla_totalCheckins.txt', 'filtered_total.txt', 'user_id_map.txt', 'item_id_map.txt', 'train.txt', 'test.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "    \n",
    "    @property\n",
    "    def ziped_file_name(self) -> str:\n",
    "        return 'loc-gowalla_totalCheckins.txt.gz'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        import gzip\n",
    "\n",
    "        if not osp.isfile(osp.join(self.root, 'loc-gowalla_totalCheckins.txt.gz')):\n",
    "            download_url(f'{self.url}', self.root)\n",
    "        if not osp.isfile(osp.join(self.root,'raw/loc-gowalla_totalCheckins.txt')): \n",
    "            os.system(f'gzip -d {osp.join(self.root,\"loc-gowalla_totalCheckins.txt.gz\")}')\n",
    "            os.system(f'mv {osp.join(self.root,\"raw/loc-gowalla_totalCheckins.txt\")} {osp.join(self.root,\"loc-gowalla_totalCheckins.txt.gz\")}')\n",
    "    \n",
    "    def core_filter(self, df, threshold):\n",
    "\n",
    "        df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[0]),sep = '\\t', names = ['user', 'time', 'long', 'lat', 'item'])\n",
    "        \n",
    "        filtered_df = self.filtering(df, threshold)\n",
    "        processed_df, user_id, item_id  = self.refactoring_from_0(filtered_df)\n",
    "\n",
    "        processed_df.to_csv(osp.join(self.raw_dir, self.raw_file_names[1]),sep=\" \", index=False, header=None)\n",
    "        user_id.to_csv(osp.join(self.raw_dir, self.raw_file_names[2]),sep=\" \", index=False, header=None)\n",
    "        item_id.to_csv(osp.join(self.raw_dir, self.raw_file_names[3]),sep=\" \", index=False, header=None)\n",
    "\n",
    "        return processed_df\n",
    "\n",
    "    def refactoring_from_0(self, df):\n",
    "        out_df = pd.DataFrame() \n",
    "        \n",
    "        original_uid = np.sort(df['user'].unique())\n",
    "        original_iid = np.sort(df['item'].unique())\n",
    "\n",
    "        u_range = range(len(original_uid))\n",
    "        i_range = range(len(original_iid))\n",
    "\n",
    "        uid_mapping = { o_id: n_id for o_id, n_id in zip(original_uid, u_range)} # 원래 유저 아이디 (중간중간 비어있음) : 순서대로 유저 아이디\n",
    "        iid_mapping = { o_id: n_id for o_id, n_id in zip(original_iid,i_range)} # 원래 아이템 아이디 : 순서대로 아이템 아이디\n",
    "\n",
    "        uid_map = pd.DataFrame({'o_id' : list(uid_mapping.keys()), 'n_id' : list(uid_mapping.values())})\n",
    "\n",
    "        iid_map = pd.DataFrame({'o_id' : list(iid_mapping.keys()),'n_id':list(iid_mapping.values())})\n",
    "\n",
    "\n",
    "        out_df['user'] = df['user'].map(uid_mapping)\n",
    "        out_df['item'] = df['item'].map(iid_mapping)\n",
    "        out_df['time'] = df['time']\n",
    "        return out_df, uid_map, iid_map\n",
    "\n",
    "    def filtering(self, df, threshold) :\n",
    "        fdf = df.drop_duplicates(subset=['user', 'item'], keep='first')\n",
    "        while fdf.user.value_counts().min() < threshold or fdf.item.value_counts().min() < threshold:\n",
    "            df_item = fdf.groupby('item').count()\n",
    "            df_item = df_item[df_item.user < threshold]\n",
    "            li = df_item.index.to_list()\n",
    "            fdf = fdf.drop(fdf.loc[fdf.item.isin(li)].index)\n",
    "\n",
    "            df_usr = fdf.groupby('user').count()\n",
    "            df_usr = df_usr[df_usr.item < threshold]\n",
    "            li = df_usr.index.to_list()\n",
    "            fdf = fdf.drop(fdf.loc[fdf.user.isin(li)].index)\n",
    "\n",
    "            # print(f\"Total Edges : {len(fdf)}\\nTotal User : {len(fdf['user'].unique())}\\nTotal item : {len(fdf['item'].unique())} \\\n",
    "            #             \\nMin Interaction Per user : {fdf.user.value_counts().min()} \\\n",
    "            #             \\nMax Interaction Per user : {fdf.user.value_counts().max()} \\\n",
    "            #             \\nAvg Interaction Per user : {fdf.user.value_counts().mean()}\\\n",
    "            #             \\nMin Interaction Per item : {fdf.item.value_counts().min()} \\\n",
    "            #             \\nMax Interaction Per item : {fdf.item.value_counts().max()} \\\n",
    "            #             \\nAvg Interaction Per item : {fdf.item.value_counts().mean()}\")\n",
    "        \n",
    "        fdf = fdf.reset_index().drop(columns = ['index'])\n",
    "        return fdf\n",
    "\n",
    "    def process(self) -> None:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        data = HeteroData()\n",
    "        attr_names = ['edge_index', 'edge_label_index']\n",
    "        # Process number of nodes for each node type:\n",
    "        node_types = ['user', 'item']\n",
    "\n",
    "        if osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[4]}\")) \\\n",
    "            and osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[5]}\")):\n",
    "            # Process edge information for training and testing:\n",
    "\n",
    "            for path, node_type in zip(self.raw_paths[2:4], node_types):\n",
    "                df = pd.read_csv(path, sep=' ', header= None)\n",
    "                data[node_type].num_nodes = len(df)\n",
    "\n",
    "            for path, attr_name in zip(self.raw_paths[4:], attr_names):\n",
    "                temp_df = pd.read_csv(path, names = ['user', 'item', 'time'], header = None)\n",
    "                rows = temp_df['user'].values\n",
    "                cols = temp_df['item'].values\n",
    "                index = torch.tensor([rows, cols])\n",
    "\n",
    "                data['user', 'rates', 'item'][attr_name] = index\n",
    "                if attr_name == 'edge_index':\n",
    "                    data['item', 'rated_by', 'user'][attr_name] = index.flip([0])\n",
    "\n",
    "        else:\n",
    "            if osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[1]}\")) \\\n",
    "                and osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[2]}\")) \\\n",
    "                    and osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[3]}\")):\n",
    "                df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[1]), sep = \" \", names = ['user', 'item', 'time'], header = None)\n",
    "            else:\n",
    "                df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[0]),  names = ['user', 'time', 'long', 'lat', 'item'], header = None)\n",
    "                self.core_filter(df, self.core)\n",
    "                df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[1]), sep = \" \", names = ['user', 'item', 'time'], header = None)\n",
    "\n",
    "            tr, test = train_test_split(df, test_size = 0.2)\n",
    "            tr.to_csv(osp.join(self.raw_dir, self.raw_file_names[4]), index = False,header = False)\n",
    "            test.to_csv(osp.join(self.raw_dir, self.raw_file_names[5]), index = False, header = False)\n",
    "\n",
    "            for path, node_type in zip(self.raw_paths[2:4], node_types):\n",
    "                df = pd.read_csv(path, sep=' ', header= None)\n",
    "                data[node_type].num_nodes = len(df)\n",
    "\n",
    "            for temp_df, attr_name in zip([tr,test],attr_names):\n",
    "                rows = temp_df['user'].values\n",
    "                cols = temp_df['item'].values\n",
    "                index = torch.tensor([rows, cols])\n",
    "\n",
    "                data['user', 'rates', 'item'][attr_name] = index\n",
    "                if attr_name == 'edge_index':\n",
    "                    data['item', 'rated_by', 'user'][attr_name] = index.flip([0])\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        self.save([data], self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join('./', 'data', 'Gowalla')\n",
    "dataset = Gowalla(path, core = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=52984 },\n",
       "  item={ num_nodes=121865 },\n",
       "  (user, rates, item)={\n",
       "    edge_index=[2, 2641256],\n",
       "    edge_label_index=[2, 660315],\n",
       "  },\n",
       "  (item, rated_by, user)={ edge_index=[2, 2641256] }\n",
       ")"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
