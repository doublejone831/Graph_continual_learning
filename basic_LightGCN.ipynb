{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "#torch 전에 할댕해줘야함\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import AmazonBook, MovieLens100K\n",
    "from torch_geometric.nn import LightGCN\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.data import InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   5,    9,   11,  ...,  933,    9,  681],\n",
       "        [1682, 1682, 1682,  ..., 2140, 2141, 2143]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ml 1m \n",
    "path = osp.join('./', 'data', 'ML1M')\n",
    "dataset = MovieLens100K(path)\n",
    "dataset.process()\n",
    "data = dataset[0]\n",
    "num_users, num_books = data['user'].num_nodes, data['movie'].num_nodes\n",
    "data = data.to_homogeneous().to(device)\n",
    "# 이새끼 호모지니어스로 바꾸면 엣지 라벨 순서가 바뀌어 버림\n",
    "data.edge_label_index = torch.stack([data.edge_label_index[1],data.edge_label_index[0]], dim = 0)\n",
    "data.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아마존\n",
    "path = osp.join('./', 'data', 'Amazon')\n",
    "dataset = AmazonBook(path)\n",
    "data = dataset[0]\n",
    "num_users, num_books = data['user'].num_nodes, data['book'].num_nodes\n",
    "data = data.to_homogeneous().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import HeteroData, InMemoryDataset, download_url\n",
    "class Gowalla(InMemoryDataset):\n",
    "    url = 'https://snap.stanford.edu/data/loc-gowalla_totalCheckins.txt.gz'\n",
    "  \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "        core: int = None,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform, pre_transform,\n",
    "                         force_reload=force_reload)\n",
    "        self.core = core\n",
    "        self.load(self.processed_paths[0], data_cls=HeteroData)\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return ['loc-gowalla_totalCheckins.txt', 'filtered_total.txt', 'user_id_map.txt', 'item_id_map.txt', 'train.txt', 'test.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "    \n",
    "    @property\n",
    "    def ziped_file_name(self) -> str:\n",
    "        return 'loc-gowalla_totalCheckins.txt.gz'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        import gzip\n",
    "\n",
    "        if not osp.isfile(osp.join(self.root, 'loc-gowalla_totalCheckins.txt.gz')):\n",
    "            download_url(f'{self.url}', self.root)\n",
    "        if not osp.isfile(osp.join(self.root,'raw/loc-gowalla_totalCheckins.txt')): \n",
    "            os.system(f'gzip -d {osp.join(self.root,\"loc-gowalla_totalCheckins.txt.gz\")}')\n",
    "            os.system(f'mv {osp.join(self.root,\"raw/loc-gowalla_totalCheckins.txt\")} {osp.join(self.root,\"loc-gowalla_totalCheckins.txt.gz\")}')\n",
    "    \n",
    "    def core_filter(self, df, threshold):\n",
    "\n",
    "        df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[0]),sep = '\\t', names = ['user', 'time', 'long', 'lat', 'item'])\n",
    "        \n",
    "        filtered_df = self.filtering(df, threshold)\n",
    "        processed_df, user_id, item_id  = self.refactoring_from_0(filtered_df)\n",
    "\n",
    "        processed_df.to_csv(osp.join(self.raw_dir, self.raw_file_names[1]),sep=\" \", index=False, header=None)\n",
    "        user_id.to_csv(osp.join(self.raw_dir, self.raw_file_names[2]),sep=\" \", index=False, header=None)\n",
    "        item_id.to_csv(osp.join(self.raw_dir, self.raw_file_names[3]),sep=\" \", index=False, header=None)\n",
    "\n",
    "        return processed_df\n",
    "\n",
    "    def refactoring_from_0(self, df):\n",
    "        out_df = pd.DataFrame() \n",
    "        \n",
    "        original_uid = np.sort(df['user'].unique())\n",
    "        original_iid = np.sort(df['item'].unique())\n",
    "\n",
    "        u_range = range(len(original_uid))\n",
    "        i_range = range(len(original_iid))\n",
    "\n",
    "        uid_mapping = { o_id: n_id for o_id, n_id in zip(original_uid, u_range)} # 원래 유저 아이디 (중간중간 비어있음) : 순서대로 유저 아이디\n",
    "        iid_mapping = { o_id: n_id for o_id, n_id in zip(original_iid,i_range)} # 원래 아이템 아이디 : 순서대로 아이템 아이디\n",
    "\n",
    "        uid_map = pd.DataFrame({'o_id' : list(uid_mapping.keys()), 'n_id' : list(uid_mapping.values())})\n",
    "\n",
    "        iid_map = pd.DataFrame({'o_id' : list(iid_mapping.keys()),'n_id':list(iid_mapping.values())})\n",
    "\n",
    "\n",
    "        out_df['user'] = df['user'].map(uid_mapping)\n",
    "        out_df['item'] = df['item'].map(iid_mapping)\n",
    "        out_df['time'] = df['time']\n",
    "        return out_df, uid_map, iid_map\n",
    "\n",
    "    def filtering(self, df, threshold) :\n",
    "        fdf = df.drop_duplicates(subset=['user', 'item'], keep='first')\n",
    "        while fdf.user.value_counts().min() < threshold or fdf.item.value_counts().min() < threshold:\n",
    "            df_item = fdf.groupby('item').count()\n",
    "            df_item = df_item[df_item.user < threshold]\n",
    "            li = df_item.index.to_list()\n",
    "            fdf = fdf.drop(fdf.loc[fdf.item.isin(li)].index)\n",
    "\n",
    "            df_usr = fdf.groupby('user').count()\n",
    "            df_usr = df_usr[df_usr.item < threshold]\n",
    "            li = df_usr.index.to_list()\n",
    "            fdf = fdf.drop(fdf.loc[fdf.user.isin(li)].index)\n",
    "\n",
    "            # print(f\"Total Edges : {len(fdf)}\\nTotal User : {len(fdf['user'].unique())}\\nTotal item : {len(fdf['item'].unique())} \\\n",
    "            #             \\nMin Interaction Per user : {fdf.user.value_counts().min()} \\\n",
    "            #             \\nMax Interaction Per user : {fdf.user.value_counts().max()} \\\n",
    "            #             \\nAvg Interaction Per user : {fdf.user.value_counts().mean()}\\\n",
    "            #             \\nMin Interaction Per item : {fdf.item.value_counts().min()} \\\n",
    "            #             \\nMax Interaction Per item : {fdf.item.value_counts().max()} \\\n",
    "            #             \\nAvg Interaction Per item : {fdf.item.value_counts().mean()}\")\n",
    "        \n",
    "        fdf = fdf.reset_index().drop(columns = ['index'])\n",
    "        return fdf\n",
    "\n",
    "    def process(self) -> None:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        data = HeteroData()\n",
    "        attr_names = ['edge_index', 'edge_label_index']\n",
    "        # Process number of nodes for each node type:\n",
    "        node_types = ['user', 'item']\n",
    "\n",
    "        if osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[4]}\")) \\\n",
    "            and osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[5]}\")):\n",
    "            # Process edge information for training and testing:\n",
    "\n",
    "            for path, node_type in zip(self.raw_paths[2:4], node_types):\n",
    "                df = pd.read_csv(path, sep=' ', header= None)\n",
    "                data[node_type].num_nodes = len(df)\n",
    "\n",
    "            for path, attr_name in zip(self.raw_paths[4:], attr_names):\n",
    "                temp_df = pd.read_csv(path, names = ['user', 'item', 'time'], header = None)\n",
    "                rows = temp_df['user'].values\n",
    "                cols = temp_df['item'].values\n",
    "                index = torch.tensor([rows, cols])\n",
    "\n",
    "                data['user', 'rates', 'item'][attr_name] = index\n",
    "                if attr_name == 'edge_index':\n",
    "                    data['item', 'rated_by', 'user'][attr_name] = index.flip([0])\n",
    "\n",
    "        else:\n",
    "            if osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[1]}\")) \\\n",
    "                and osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[2]}\")) \\\n",
    "                    and osp.isfile(osp.join(self.root,f\"raw/{self.raw_file_names[3]}\")):\n",
    "                df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[1]), sep = \" \", names = ['user', 'item', 'time'], header = None)\n",
    "            else:\n",
    "                df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[0]),  names = ['user', 'time', 'long', 'lat', 'item'], header = None)\n",
    "                self.core_filter(df, self.core)\n",
    "                df = pd.read_csv(osp.join(self.raw_dir, self.raw_file_names[1]), sep = \" \", names = ['user', 'item', 'time'], header = None)\n",
    "\n",
    "            tr, test = train_test_split(df, test_size = 0.2)\n",
    "            tr.to_csv(osp.join(self.raw_dir, self.raw_file_names[4]), index = False,header = False)\n",
    "            test.to_csv(osp.join(self.raw_dir, self.raw_file_names[5]), index = False, header = False)\n",
    "\n",
    "            for path, node_type in zip(self.raw_paths[2:4], node_types):\n",
    "                df = pd.read_csv(path, sep=' ', header= None)\n",
    "                data[node_type].num_nodes = len(df)\n",
    "\n",
    "            for temp_df, attr_name in zip([tr,test],attr_names):\n",
    "                rows = temp_df['user'].values\n",
    "                cols = temp_df['item'].values\n",
    "                index = torch.tensor([rows, cols])\n",
    "\n",
    "                data['user', 'rates', 'item'][attr_name] = index\n",
    "                if attr_name == 'edge_index':\n",
    "                    data['item', 'rated_by', 'user'][attr_name] = index.flip([0])\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        self.save([data], self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gowalla\n",
    "path = osp.join('./', 'data', 'Gowalla')\n",
    "dataset = Gowalla(path)\n",
    "dataset.process()\n",
    "data = dataset[0]\n",
    "num_users, num_books = data['user'].num_nodes, data['item'].num_nodes\n",
    "data = data.to_homogeneous().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=29858 },\n",
       "  item={ num_nodes=40988 },\n",
       "  (user, rates, item)={\n",
       "    edge_index=[2, 821971],\n",
       "    edge_label_index=[2, 205493],\n",
       "  },\n",
       "  (item, rated_by, user)={ edge_index=[2, 821971] }\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all message passing edges as training labels:\n",
    "batch_size = 8192\n",
    "mask = data.edge_index[0] < data.edge_index[1]\n",
    "train_edge_label_index = data.edge_index[:, mask]\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    range(train_edge_label_index.size(1)),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "model = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    for index in train_loader:\n",
    "        # Sample positive and negative labels.\n",
    "        pos_edge_label_index = train_edge_label_index[:, index]\n",
    "        neg_edge_label_index = torch.stack([\n",
    "            pos_edge_label_index[0],\n",
    "            torch.randint(num_users, num_users + num_books,\n",
    "                          (index.numel(), ), device=device)\n",
    "        ], dim=0)\n",
    "        edge_label_index = torch.cat([\n",
    "            pos_edge_label_index,\n",
    "            neg_edge_label_index,\n",
    "        ], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_rank, neg_rank = model(data.edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=edge_label_index.unique(),\n",
    "            lambda_reg = 0.001\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "        total_examples += pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(k: int):\n",
    "    emb = model.get_embedding(data.edge_index)\n",
    "    user_emb, book_emb = emb[:num_users], emb[num_users:]\n",
    "\n",
    "    precision = recall = total_examples = 0\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = min(start + batch_size, num_users)\n",
    "        logits = user_emb[start:end] @ book_emb.t()\n",
    "        # Exclude training edges:\n",
    "        mask = ((train_edge_label_index[0] >= start) &\n",
    "                (train_edge_label_index[0] < end))\n",
    "        logits[train_edge_label_index[0, mask] - start,\n",
    "                train_edge_label_index[1, mask] - num_users] = float('-inf')\n",
    "\n",
    "        # Computing precision and recall:\n",
    "        ground_truth = torch.zeros_like(logits, dtype=torch.bool)\n",
    "        mask = ((data.edge_label_index[0] >= start) &\n",
    "                (data.edge_label_index[0] < end))\n",
    "        ground_truth[data.edge_label_index[0, mask] - start,\n",
    "                        data.edge_label_index[1, mask] - num_users] = True\n",
    "        node_count = degree(data.edge_label_index[0, mask] - start,\n",
    "                                num_nodes=logits.size(0))\n",
    "\n",
    "        topk_index = logits.topk(k, dim=-1).indices\n",
    "        isin_mat = ground_truth.gather(1, topk_index)\n",
    "\n",
    "        precision += float((isin_mat.sum(dim=-1) / k).sum())\n",
    "        recall += float((isin_mat.sum(dim=-1) / node_count.clamp(1e-6)).sum())\n",
    "        total_examples += int((node_count > 0).sum())\n",
    "\n",
    "    return precision / total_examples, recall / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:01<31:59,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.6382, Precision@20: 0.0194, Recall@20: 0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:21<31:28,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.1418, Precision@20: 0.0273, Recall@20: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [00:40<31:12,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 0.1102, Precision@20: 0.0307, Recall@20: 0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [00:59<30:56,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Loss: 0.0961, Precision@20: 0.0328, Recall@20: 0.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [01:18<30:39,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Loss: 0.0875, Precision@20: 0.0345, Recall@20: 0.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [01:37<30:20,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: 0.0815, Precision@20: 0.0360, Recall@20: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 61/1000 [01:56<30:05,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 060, Loss: 0.0777, Precision@20: 0.0373, Recall@20: 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1000 [02:16<29:33,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 070, Loss: 0.0745, Precision@20: 0.0383, Recall@20: 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1000 [02:35<29:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 080, Loss: 0.0721, Precision@20: 0.0392, Recall@20: 0.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 91/1000 [02:54<28:39,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 090, Loss: 0.0708, Precision@20: 0.0402, Recall@20: 0.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [03:12<28:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.0686, Precision@20: 0.0408, Recall@20: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 111/1000 [03:31<27:41,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Loss: 0.0676, Precision@20: 0.0416, Recall@20: 0.1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 121/1000 [03:50<27:22,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, Loss: 0.0664, Precision@20: 0.0421, Recall@20: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 131/1000 [04:08<27:03,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, Loss: 0.0654, Precision@20: 0.0427, Recall@20: 0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 141/1000 [04:27<26:56,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, Loss: 0.0648, Precision@20: 0.0433, Recall@20: 0.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [04:46<26:40,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Loss: 0.0642, Precision@20: 0.0436, Recall@20: 0.1497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 161/1000 [05:05<26:37,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Loss: 0.0635, Precision@20: 0.0440, Recall@20: 0.1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 171/1000 [05:24<26:26,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, Loss: 0.0630, Precision@20: 0.0445, Recall@20: 0.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [05:43<26:06,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss: 0.0621, Precision@20: 0.0448, Recall@20: 0.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 191/1000 [06:02<25:46,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss: 0.0617, Precision@20: 0.0452, Recall@20: 0.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [06:21<25:35,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 0.0614, Precision@20: 0.0455, Recall@20: 0.1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 211/1000 [06:41<25:15,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Loss: 0.0614, Precision@20: 0.0457, Recall@20: 0.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 221/1000 [07:00<24:59,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Loss: 0.0612, Precision@20: 0.0460, Recall@20: 0.1581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 231/1000 [07:19<24:32,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230, Loss: 0.0610, Precision@20: 0.0463, Recall@20: 0.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 241/1000 [07:38<24:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240, Loss: 0.0609, Precision@20: 0.0466, Recall@20: 0.1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [07:57<24:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250, Loss: 0.0603, Precision@20: 0.0468, Recall@20: 0.1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 261/1000 [08:17<23:43,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260, Loss: 0.0604, Precision@20: 0.0469, Recall@20: 0.1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 271/1000 [08:36<23:16,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Loss: 0.0600, Precision@20: 0.0471, Recall@20: 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 281/1000 [08:55<23:05,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Loss: 0.0600, Precision@20: 0.0473, Recall@20: 0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 291/1000 [09:14<22:40,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290, Loss: 0.0599, Precision@20: 0.0476, Recall@20: 0.1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [09:33<22:16,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Loss: 0.0595, Precision@20: 0.0476, Recall@20: 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 311/1000 [09:53<21:57,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310, Loss: 0.0595, Precision@20: 0.0477, Recall@20: 0.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [10:12<21:45,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, Loss: 0.0593, Precision@20: 0.0479, Recall@20: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 331/1000 [10:31<21:23,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330, Loss: 0.0592, Precision@20: 0.0480, Recall@20: 0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 341/1000 [10:50<21:03,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Loss: 0.0588, Precision@20: 0.0480, Recall@20: 0.1644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [11:09<20:41,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Loss: 0.0589, Precision@20: 0.0481, Recall@20: 0.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 361/1000 [11:28<20:25,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss: 0.0590, Precision@20: 0.0483, Recall@20: 0.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 371/1000 [11:48<20:08,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370, Loss: 0.0590, Precision@20: 0.0484, Recall@20: 0.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 381/1000 [12:07<19:52,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380, Loss: 0.0586, Precision@20: 0.0486, Recall@20: 0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 391/1000 [12:26<19:25,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 390, Loss: 0.0584, Precision@20: 0.0487, Recall@20: 0.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [12:45<19:08,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Loss: 0.0584, Precision@20: 0.0487, Recall@20: 0.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 411/1000 [13:04<18:51,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 410, Loss: 0.0586, Precision@20: 0.0488, Recall@20: 0.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 421/1000 [13:24<18:33,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420, Loss: 0.0587, Precision@20: 0.0487, Recall@20: 0.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 431/1000 [13:43<18:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 430, Loss: 0.0584, Precision@20: 0.0490, Recall@20: 0.1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 441/1000 [14:02<17:40,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440, Loss: 0.0585, Precision@20: 0.0489, Recall@20: 0.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [14:21<17:36,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450, Loss: 0.0580, Precision@20: 0.0490, Recall@20: 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 461/1000 [14:41<17:19,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460, Loss: 0.0580, Precision@20: 0.0492, Recall@20: 0.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 471/1000 [15:00<16:37,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470, Loss: 0.0581, Precision@20: 0.0492, Recall@20: 0.1681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 481/1000 [15:19<16:28,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480, Loss: 0.0581, Precision@20: 0.0493, Recall@20: 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [15:38<16:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 490, Loss: 0.0578, Precision@20: 0.0492, Recall@20: 0.1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [15:57<15:39,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Loss: 0.0582, Precision@20: 0.0492, Recall@20: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 511/1000 [16:16<15:35,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 510, Loss: 0.0580, Precision@20: 0.0495, Recall@20: 0.1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 521/1000 [16:35<15:17,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 520, Loss: 0.0577, Precision@20: 0.0495, Recall@20: 0.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 531/1000 [16:54<15:03,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 530, Loss: 0.0579, Precision@20: 0.0494, Recall@20: 0.1693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 541/1000 [17:13<14:37,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 540, Loss: 0.0578, Precision@20: 0.0496, Recall@20: 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [17:32<14:15,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 550, Loss: 0.0577, Precision@20: 0.0496, Recall@20: 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 557/1000 [17:44<14:00,  1.90s/it]"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "best_model = model.get_embedding(data.edge_index).detach()\n",
    "best_init = model.embedding.weight.detach()\n",
    "p = 0\n",
    "for epoch in tqdm(range(0, 1000)):\n",
    "    loss = train()\n",
    "    precision, recall = test(k=20)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Precision@20: '\n",
    "            f'{precision:.4f}, Recall@20: {recall:.4f}')\n",
    "        if recall > best:\n",
    "            p = 0\n",
    "            best_model = model.get_embedding(data.edge_index).detach()\n",
    "            best_init = model.embedding.weight.detach()\n",
    "            best = recall\n",
    "        else:\n",
    "            p += 1\n",
    "            if p > 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
